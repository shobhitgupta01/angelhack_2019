{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1:\n",
    "Perform statistical parsing/tagging on a document in JSON format\n",
    "\n",
    "INPUTS: JSON doc for the text input  \n",
    "OUTPUT: JSON format `ParsedGraf(id, sha1, graf)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from cmd_pytextrank import pytextrank\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_terms(text_doc):\n",
    "    path_stage1 = \"o1.json\"\n",
    "    with open(path_stage1, 'w') as f:\n",
    "        for graf in pytextrank.parse_doc(pytextrank.json_iter(text_doc)):\n",
    "            f.write(\"%s\\n\" % pytextrank.pretty_print(graf._asdict()))\n",
    "\n",
    "    graph, ranks = pytextrank.text_rank(path_stage1)\n",
    "    pytextrank.render_ranks(graph, ranks)\n",
    "\n",
    "    result = []\n",
    "    count = 0;\n",
    "    for rl in pytextrank.normalize_key_phrases(path_stage1, ranks):\n",
    "        count += 1\n",
    "        if count>5: break\n",
    "#         print(pytextrank.pretty_print(rl))\n",
    "        result.append(ast.literal_eval(pytextrank.pretty_print(rl))[:2])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['car', 0.08623640497600257],\n",
       " ['engine specs', 0.05427824354964387],\n",
       " ['looking car', 0.05208175460255698],\n",
       " ['model name', 0.047578672329223304],\n",
       " ['sports car', 0.043118202488001287]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_doc = \"./test_data/news_group1.json\"\n",
    "get_key_terms(text_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# path_stage0 = \"mih.json\"\n",
    "# path_stage1 = \"o1.json\"\n",
    "\n",
    "# with open(path_stage1, 'w') as f:\n",
    "#     for graf in pytextrank.parse_doc(pytextrank.json_iter(path_stage0)):\n",
    "#         f.write(\"%s\\n\" % pytextrank.pretty_print(graf._asdict()))\n",
    "#         # to view output in this notebook\n",
    "# #         print(pytextrank.pretty_print(graf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2:\n",
    "Collect and normalize the key phrases from a parsed document\n",
    "\n",
    "INPUTS: `<stage1>`  \n",
    "OUTPUT: JSON format `RankedLexeme(text, rank, ids, pos)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_stage1 = \"o1.json\"\n",
    "\n",
    "# graph, ranks = pytextrank.text_rank(path_stage1)\n",
    "# pytextrank.render_ranks(graph, ranks)\n",
    "\n",
    "# count = 0;\n",
    "# for rl in pytextrank.normalize_key_phrases(path_stage1, ranks):\n",
    "#     count += 1\n",
    "#     if count>5: break\n",
    "#     print(ast.literal_eval(pytextrank.pretty_print(rl))[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import pylab as plt\n",
    "\n",
    "# nx.draw(graph, with_labels=True) \n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3:\n",
    "Calculate a significance weight for each sentence, using MinHash to approximate a Jaccard distance from key phrases determined by TextRank\n",
    "\n",
    "INPUTS: `<stage1> <stage2>`  \n",
    "OUTPUT: JSON format `SummarySent(dist, idx, text)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_stage1 = \"o1.json\"\n",
    "# path_stage2 = \"o2.json\"\n",
    "# path_stage3 = \"o3.json\"\n",
    "\n",
    "# kernel = pytextrank.rank_kernel(path_stage2)\n",
    "\n",
    "# with open(path_stage3, 'w') as f:\n",
    "#     for s in pytextrank.top_sentences(kernel, path_stage1):\n",
    "#         f.write(pytextrank.pretty_print(s._asdict()))\n",
    "#         f.write(\"\\n\")\n",
    "#         # to view output in this notebook\n",
    "#         print(pytextrank.pretty_print(s._asdict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 4:\n",
    "Summarize a document based on most significant sentences and key phrases\n",
    "\n",
    "INPUTS: `<stage2> <stage3>`  \n",
    "OUTPUT: Markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_stage2 = \"o2.json\"\n",
    "# path_stage3 = \"o3.json\"\n",
    "\n",
    "# p\n",
    "# phrases = \", \".join(set([p for p in pytextrank.limit_keyphrases(path_stage2, phrase_limit=4)]))\n",
    "# # sent_iter = sorted(pytextrank.limit_sentences(path_stage3, word_limit=150), key=lambda x: x[1])\n",
    "# # s = []\n",
    "\n",
    "# # for sent_text, idx in sent_iter:\n",
    "# #     s.append(pytextrank.make_sentence(sent_text))\n",
    "\n",
    "# # graf_text = \" \".join(s)\n",
    "# # print(\"**excerpts:** %s\\n\\n**keywords:** %s\" % (graf_text, phrases,))\n",
    "# print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
