{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1:\n",
    "Perform statistical parsing/tagging on a document in JSON format\n",
    "\n",
    "INPUTS: JSON doc for the text input  \n",
    "OUTPUT: JSON format `ParsedGraf(id, sha1, graf)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from cmd_pytextrank import pytextrank\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_terms(text_doc):\n",
    "    path_stage1 = \"o1.json\"\n",
    "    with open(path_stage1, 'w') as f:\n",
    "        for graf in pytextrank.parse_doc(pytextrank.json_iter(text_doc)):\n",
    "            f.write(\"%s\\n\" % pytextrank.pretty_print(graf._asdict()))\n",
    "\n",
    "    graph, ranks = pytextrank.text_rank(path_stage1)\n",
    "    pytextrank.render_ranks(graph, ranks)\n",
    "\n",
    "    result = []\n",
    "    count = 0;\n",
    "    for rl in pytextrank.normalize_key_phrases(path_stage1, ranks):\n",
    "        count += 1\n",
    "        if count>5: break\n",
    "#         print(pytextrank.pretty_print(rl))\n",
    "        result.append(ast.literal_eval(pytextrank.pretty_print(rl))[:2])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_doc = \"./test_data/news_group1.json\"\n",
    "top_words = get_key_terms(text_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linguistics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dbm\n",
    "fh = open('./wordnet-domains-sentiwords-master/wn-domains/wn-domains-3.2-20070223', 'r')\n",
    "dbdomains.close()\n",
    "dbdomains = dbm.open('dbdomains', 'c')\n",
    "for line in fh:\n",
    "    offset, domain = line.split('\\t')\n",
    "    if offset==\"06423378-n\": print(domain)\n",
    "#     print(offset, domain)\n",
    "    dbdomains[offset[:-2]] = domain\n",
    "\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('motorcycle.n.01')\n",
      "03790512\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ss = wordnet.synsets('bike')[0]\n",
    "print(ss)\n",
    "ssid = str(ss.offset()).zfill(8)\n",
    "print(ssid)\n",
    "print(dbdomains.get(ssid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "None\n",
      "engine specs\n",
      "looking car\n",
      "model name\n",
      "sports car\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "for x in top_words:\n",
    "    print(x[0])\n",
    "    if len(wordnet.synsets(x[0]))>0:\n",
    "        ss = wordnet.synsets(x[0])[0]\n",
    "        ssid = str(ss.offset()).zfill(8)\n",
    "        print(dbdomains.get(ssid))\n",
    "#         print(dbdomains.get('0' + str(wordnet.synsets(x[0])[0].offset())))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Loading the Wordnet domains.\n",
    "domain2synsets = defaultdict(list)\n",
    "synset2domains = defaultdict(list)\n",
    "domain_set = set()\n",
    "for i in open('./wordnet-domains-sentiwords-master/wn-domains/wn-domains-3.2-20070223', 'r'):\n",
    "    ssid, doms = i.strip().split('\\t')\n",
    "    domain_set.add(doms)\n",
    "#     print(ssid, doms)\n",
    "    doms = doms.split()\n",
    "    synset2domains[ssid] = doms\n",
    "    for d in doms:\n",
    "        domain2synsets[d].append(ssid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Synset.offset of Synset('politician.n.01')>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('politician')[0].offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00001740-n\n",
      "00002056-n\n",
      "00002342-n\n",
      "00002452-n\n",
      "00002560-n\n",
      "00002645-n\n",
      "00003009-n\n",
      "00003226-n\n",
      "00004358-n\n"
     ]
    }
   ],
   "source": [
    "count = 0;\n",
    "for x in synset2domains:\n",
    "    count += 1\n",
    "    if count>=10: break\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('able.a.01') 00001740-a ['quality']\n",
      "Synset('easy.s.12') 00015097-s ['factotum']\n",
      "Synset('unambitious.a.01') 00105023-a ['factotum']\n",
      "Synset('unresentful.a.01') 00117106-a ['psychoanalysis']\n",
      "Synset('militarized.s.01') 00142825-s ['factotum']\n",
      "Synset('free-swimming.s.01') 00160288-s ['factotum']\n",
      "Synset('self-locking.s.01') 00182418-s ['factotum']\n",
      "Synset('addressable.s.01') 00183932-s ['factotum']\n",
      "Synset('stiff-backed.s.01') 00200854-s ['factotum']\n",
      "Synset('spiny-edged.s.01') 00259098-s ['factotum']\n",
      "Synset('murky.s.02') 00276689-s ['factotum']\n",
      "Synset('rose-purple.s.01') 00382594-s ['color']\n",
      "Synset('lead-colored.s.01') 00398482-s ['factotum']\n",
      "Synset('detonative.s.01') 00474883-s ['geology']\n",
      "Synset('tenderhearted.s.02') 00506852-s ['factotum']\n",
      "Synset('bunchy.s.01') 00538891-s ['factotum']\n",
      "Synset('claustrophobic.s.01') 00558612-s ['factotum']\n",
      "Synset('incorrupt.a.01') 00622581-a ['banking']\n",
      "Synset('dangerous.s.02') 00651039-s ['factotum']\n",
      "Synset('decussate.s.01') 00653044-s ['factotum']\n",
      "Synset('indelicate.s.03') 00684054-s ['factotum']\n",
      "Synset('bibulous.s.01') 00798491-s ['factotum']\n",
      "Synset('reluctant.s.03') 00811969-s ['factotum']\n",
      "Synset('ice-clogged.s.01') 01079143-s ['factotum']\n",
      "Synset('dense.s.03') 01185264-s ['factotum']\n",
      "Synset('dicky.s.01') 01274741-s ['factotum']\n",
      "Synset('educational.s.02') 01324565-s ['factotum']\n",
      "Synset('embedded.s.02') 01328419-s ['factotum']\n",
      "Synset('apathetic.s.02') 01342949-s ['factotum']\n",
      "Synset('bracing.s.01') 01357027-s ['factotum']\n",
      "Synset('unliveried.a.01') 01424353-a ['factotum']\n",
      "Synset('close.s.12') 01447937-s ['factotum']\n",
      "Synset('matronly.s.01') 01485254-s ['factotum']\n",
      "Synset('blocked.s.01') 01653857-s ['factotum']\n",
      "Synset('basined.s.01') 01657056-s ['exchange']\n",
      "Synset('recognizable.s.01') 01747996-s ['factotum']\n"
     ]
    }
   ],
   "source": [
    "# Gets domains given synset.\n",
    "count = 0;\n",
    "for ss in wn.all_synsets():\n",
    "    count += 1\n",
    "#     print(ss.pos())\n",
    "    if count>=10000: break\n",
    "    ssid = str(ss.offset()).zfill(8) + \"-\" + ss.pos()\n",
    "#     print(ssid)\n",
    "#     print(ss)\n",
    "    if synset2domains[ssid]: # not all synsets are in WordNet Domain.\n",
    "        print(ss, ssid, synset2domains[ssid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(domain2synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gets synsets given domain.        \n",
    "# for dom in sorted(domain2synsets):\n",
    "#     print(dom, domain2synsets[dom][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
