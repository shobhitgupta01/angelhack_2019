{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1:\n",
    "Perform statistical parsing/tagging on a document in JSON format\n",
    "\n",
    "INPUTS: JSON doc for the text input  \n",
    "OUTPUT: JSON format `ParsedGraf(id, sha1, graf)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from cmd_pytextrank import pytextrank\n",
    "import sys\n",
    "import spacy\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of topics considered 363\n"
     ]
    }
   ],
   "source": [
    "news_topics = pd.read_csv(\"list_of_topics.csv\")\n",
    "print(\"No of topics considered {}\".format(len(news_topics)))\n",
    "news_topics_list = news_topics.topics\n",
    "vectors = np.array(list(map(lambda x: nlp(x).vector, news_topics_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_terms(text_doc):\n",
    "    path_stage1 = \"o1.json\"\n",
    "    with open(path_stage1, 'w') as f:\n",
    "        for graf in pytextrank.parse_doc(pytextrank.json_iter(text_doc)):\n",
    "            f.write(\"%s\\n\" % pytextrank.pretty_print(graf._asdict()))\n",
    "\n",
    "    graph, ranks = pytextrank.text_rank(path_stage1)\n",
    "    pytextrank.render_ranks(graph, ranks)\n",
    "\n",
    "    result = []\n",
    "    count = 0;\n",
    "    for rl in pytextrank.normalize_key_phrases(path_stage1, ranks):\n",
    "        count += 1\n",
    "#         if count>5: break\n",
    "#         print(pytextrank.pretty_print(rl))\n",
    "        result.append(ast.literal_eval(pytextrank.pretty_print(rl))[:2])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** CONTENT *** \n",
      "\"\n",
      "What is dengue?\n",
      "Dengue is fast emerging pandemic-prone viral disease in many parts of the world. Dengue flourishes in urban poor areas, suburbs and the countryside but also affects more affluent neighbourhoods in tropical and subtropical countries.\n",
      "Dengue is a mosquito-borne viral infection causing a severe flu-like illness and, sometimes causing a potentially lethal complication called severe dengue. The incidence of dengue has increased 30-fold over the last 50 years. Up to 50-100 million inf[...]\"\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "url = \"https://www.who.int/denguecontrol/disease/en/\"\n",
    "html = urlopen(url).read()\n",
    "\n",
    "from readability.readability import Document\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "readable_article = Document(html).summary()\n",
    "readable_title = Document(html).title()\n",
    "soup = BeautifulSoup(readable_article)\n",
    "url_dict = {}\n",
    "url_dict['id'] = 1\n",
    "url_dict['text'] = soup.text\n",
    "\n",
    "with open('./test_data/sample.json', 'w') as json_file:\n",
    "    json.dump(url_dict, json_file)\n",
    "# print(*** TITLE *** \\n\\\"' + readable_title + '\\\"\\n')\n",
    "print('*** CONTENT *** \\n\\\"' + soup.text[:500] + '[...]\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'infections': 0.8303318877200434, 'world': 0.6042749440634765, 'insects': 0.8150994469990989, 'population': 0.7107153592032549}\n"
     ]
    }
   ],
   "source": [
    "text_doc = \"./test_data/sample.json\"\n",
    "key_terms = get_key_terms(text_doc)\n",
    "\n",
    "word_vectors = list(map(lambda x: nlp(x[0]).vector, key_terms))\n",
    "NUM_CLUSTERS=5\n",
    "kmeans = cluster.KMeans(n_clusters=NUM_CLUSTERS, n_jobs=6, n_init=10, max_iter=500,\n",
    "                       random_state=0)\n",
    "kmeans.fit(word_vectors)\n",
    " \n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "result = {}\n",
    "\n",
    "for x in centroids:\n",
    "    cosine_values = list(cosine_similarity(x.reshape(1,-1), vectors)[0])\n",
    "    result[news_topics_list[cosine_values.index(max(cosine_values))]] = max(cosine_values)\n",
    "#     result.append([news_topics_list[cosine_values.index(max(cosine_values))], max(cosine_values)])\n",
    "\n",
    "sorted(result.items(), key = lambda kv:(kv[1], kv[0]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
