{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1:\n",
    "Perform statistical parsing/tagging on a document in JSON format\n",
    "\n",
    "INPUTS: JSON doc for the text input  \n",
    "OUTPUT: JSON format `ParsedGraf(id, sha1, graf)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from cmd_pytextrank import pytextrank\n",
    "import sys\n",
    "import spacy\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of topics considered 362\n"
     ]
    }
   ],
   "source": [
    "news_topics = pd.read_csv(\"list_of_topics_filtered.csv\")\n",
    "print(\"No of topics considered {}\".format(len(news_topics)))\n",
    "news_topics_list = news_topics.topics\n",
    "vectors = np.array(list(map(lambda x: nlp(x).vector, news_topics_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_terms(text_doc):\n",
    "    path_stage1 = \"o1.json\"\n",
    "    with open(path_stage1, 'w') as f:\n",
    "        for graf in pytextrank.parse_doc(pytextrank.json_iter(text_doc)):\n",
    "            f.write(\"%s\\n\" % pytextrank.pretty_print(graf._asdict()))\n",
    "\n",
    "    graph, ranks = pytextrank.text_rank(path_stage1)\n",
    "    pytextrank.render_ranks(graph, ranks)\n",
    "\n",
    "    result = []\n",
    "    count = 0;\n",
    "    for rl in pytextrank.normalize_key_phrases(path_stage1, ranks):\n",
    "        count += 1\n",
    "#         if count>5: break\n",
    "#         print(pytextrank.pretty_print(rl))\n",
    "        result.append(ast.literal_eval(pytextrank.pretty_print(rl))[:2])\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** CONTENT *** \n",
      "\"ISLAMABAD: Defence budget during the next fiscal year will remain unchanged as compared to the outgoing fiscal year in rupee terms due to the country’s dire economic condition.  \n",
      "Prime Minister Imran Khan took to Twitter on the eve of Eidul Fitr to announce that the military had “voluntarily agreed” to cut its expenditures due to “critical financial situation”. He noted the continuing “multiple security challenges” and pledged to spend the saved amount on development of the erstwhile tribal area[...]\"\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "url = \"https://www.dawn.com/news/1486778\"\n",
    "html = urlopen(url).read()\n",
    "\n",
    "from readability.readability import Document\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "readable_article = Document(html).summary()\n",
    "readable_title = Document(html).title()\n",
    "soup = BeautifulSoup(readable_article)\n",
    "url_dict = {}\n",
    "url_dict['id'] = 1\n",
    "url_dict['text'] = soup.text\n",
    "\n",
    "with open('./test_data/sample.json', 'w') as json_file:\n",
    "    json.dump(url_dict, json_file)\n",
    "# print(*** TITLE *** \\n\\\"' + readable_title + '\\\"\\n')\n",
    "print('*** CONTENT *** \\n\\\"' + soup.text[:500] + '[...]\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tax', 0.7737865159266549), ('military', 0.7453416891622034), ('government', 0.6377116884664326), ('Money', 0.6217558641482697), ('Islam', 0.4761529474548174)]\n"
     ]
    }
   ],
   "source": [
    "text_doc = \"./test_data/sample.json\"\n",
    "key_terms = get_key_terms(text_doc)\n",
    "\n",
    "word_vectors = list(map(lambda x: nlp(x[0]).vector, key_terms))\n",
    "NUM_CLUSTERS=5\n",
    "kmeans = cluster.KMeans(n_clusters=NUM_CLUSTERS, n_jobs=6, n_init=10, max_iter=500,\n",
    "                       random_state=0)\n",
    "kmeans.fit(word_vectors)\n",
    " \n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "result = {}\n",
    "\n",
    "for x in centroids:\n",
    "    cosine_values = list(cosine_similarity(x.reshape(1,-1), vectors)[0])\n",
    "    correlated_word = news_topics_list[cosine_values.index(max(cosine_values))]\n",
    "    cosine_values[cosine_values.index(max(cosine_values))] = -1\n",
    "    while correlated_word in result:\n",
    "        correlated_word = news_topics_list[cosine_values.index(max(cosine_values))]\n",
    "    \n",
    "    result[correlated_word] = max(cosine_values)\n",
    "#     result.append([news_topics_list[cosine_values.index(max(cosine_values))], max(cosine_values)])\n",
    "\n",
    "print(sorted(result.items(), key = lambda kv: -kv[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
